{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_contour_thresh(img):\n",
    "    x, y, w, h = 0, 0, 300, 300\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    thresh1 = thresh1[y:y + h, x:x + w]\n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    return img, contours, thresh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mDigit-Recognizer\u001b[m\u001b[m             project_notes\r\n",
      "README.md                    requirements.txt\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                         update_one.docx\r\n",
      "dig_rec_scratch.ipynb        update_one.pdf\r\n",
      "\u001b[34mdigit-recognizer-copy\u001b[m\u001b[m        update_one.txt\r\n",
      "final-report-dl-2018.pdf     webcam_capture.py\r\n",
      "logistic_regression_torch.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (logistic_regression_torch.py, line 48)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/anaconda/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2963\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-21cb4a1e4a67>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import logistic_regression_torch as lr_torch\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/fordhiggins/msan_files/msan631-dl/computer_vision/logistic_regression_torch.py\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    print('Epoch ' + epoch + ': ' loss.item())\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import logistic_regression_torch as lr_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "??MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST(path, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: data\n",
       "    Transforms (if any): None\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "test_batch_size = 64 # why are these different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(path, train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(path, train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__() # why are we supering ourselves?\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # not sure it matters which one we use\n",
    "        out = F.log_softmax(self.linear(x), dim = 1) # is this what I want? or wrap it in F.log_softmax()? \n",
    "        #out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "input_dim = 28\n",
    "input_size = input_dim**2\n",
    "n_classes = 10\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Creating the model object\n",
    "model = LogisticRegression(input_size, n_classes)\n",
    "\n",
    "# Initiating loss and optimizer\n",
    "# do we want SGD or Adam? read up on differences\n",
    "# want something else for loss? CEL computes softmax internally\n",
    "\n",
    "def train_epochs(model, train_dl = train_dl, n_epochs = 10, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # is this necessary?\n",
    "    optimizer = optim.SGD(parameters, lr = lr)\n",
    "    model.train()\n",
    "    for epoch in np.arange(n_epochs):\n",
    "        for i, (x, y) in enumerate(train_dl):\n",
    "            x = x.reshape(-1, input_size)\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            print('Epoch ' + str(epoch) + ': ')\n",
    "    test_loss(model, test_dl)\n",
    "\n",
    "\n",
    "def test_loss(model, test_dl = test_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    sum_loss = 0\n",
    "    preds_list = list()\n",
    "\n",
    "    for i, (x, y) in enumerate(test_dl):\n",
    "        x = x.reshape(-1, input_size)\n",
    "        batch = y.shape[0]\n",
    "        out = model(x)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        preds = torch.argmax(out, dim = 1)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        correct += preds.eq(y.data).sum().item()\n",
    "        total += batch\n",
    "        preds_list.append(preds)\n",
    "        \n",
    "    print(\"val loss and accuracy\", sum_loss/total, correct/total)\n",
    "    return preds_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      "Epoch 2: \n",
      "Epoch 4: \n",
      "val loss and accuracy 0.2786918731212616 0.9195\n"
     ]
    }
   ],
   "source": [
    "train_epochs(model, n_epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      "Epoch 2: \n",
      "Epoch 4: \n",
      "val loss and accuracy 0.28449721088409424 0.9193\n"
     ]
    }
   ],
   "source": [
    "train_epochs(model, n_epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x12a81edb0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(-1, 28**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  0,  4,  4,  2,  2,  7,  9,  9,  1,  6,  3,  2,\n",
       "         8,  9,  5,  4,  2,  5,  7,  8,  9,  1,  6,  1,  8,  5,\n",
       "         1,  1,  6,  9,  2,  8,  6,  8,  0,  7,  6,  1,  9,  4,\n",
       "         8,  5,  9,  6,  3,  3,  4,  3,  3,  3,  4,  8,  9,  8,\n",
       "         5,  6,  6,  9,  5,  1,  7,  1])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3917)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2301e+01, -4.2802e-02, -5.3405e+00, -5.1222e+00, -1.1703e+01,\n",
       "         -7.4697e+00, -7.3047e+00, -7.5752e+00, -3.5515e+00, -7.2750e+00],\n",
       "        [-1.0181e+01, -4.9038e-02, -6.3201e+00, -4.4479e+00, -7.4766e+00,\n",
       "         -4.0729e+00, -5.7585e+00, -6.5310e+00, -4.5835e+00, -6.2715e+00],\n",
       "        [-1.3986e-03, -2.1634e+01, -1.1154e+01, -9.0436e+00, -1.3884e+01,\n",
       "         -7.1985e+00, -1.1881e+01, -9.6374e+00, -8.5020e+00, -8.3293e+00],\n",
       "        [-6.3397e+00, -1.2844e+01, -8.9208e+00, -1.0168e+01, -5.3882e-02,\n",
       "         -6.5803e+00, -5.2060e+00, -5.9307e+00, -5.7475e+00, -3.2755e+00],\n",
       "        [-1.1553e+01, -1.3312e+01, -1.0907e+01, -9.8390e+00, -3.0842e-01,\n",
       "         -4.7261e+00, -6.4389e+00, -9.0482e+00, -3.3685e+00, -1.5128e+00],\n",
       "        [-1.5115e+01, -5.4320e+00, -4.4530e-02, -3.4295e+00, -2.0189e+01,\n",
       "         -1.2131e+01, -5.1969e+00, -1.8338e+01, -6.6954e+00, -1.5369e+01],\n",
       "        [-1.1881e+01, -9.6766e+00, -1.7927e-02, -4.4257e+00, -8.6833e+00,\n",
       "         -1.0827e+01, -5.4028e+00, -9.3564e+00, -7.7509e+00, -7.5583e+00],\n",
       "        [-9.8971e+00, -1.6025e+01, -1.0919e+01, -8.5810e+00, -7.9168e+00,\n",
       "         -7.6031e+00, -1.2935e+01, -8.2350e-02, -8.0100e+00, -2.5562e+00],\n",
       "        [-9.1519e+00, -2.3373e+00, -5.6752e+00, -2.9171e+00, -2.8108e+00,\n",
       "         -3.8224e+00, -4.2549e+00, -3.9370e+00, -2.6603e+00, -4.1532e-01],\n",
       "        [-5.0935e+00, -1.5400e+01, -1.0310e+01, -1.0772e+01, -4.8183e+00,\n",
       "         -6.5658e+00, -9.5774e+00, -5.1668e+00, -9.4206e-01, -5.2980e-01],\n",
       "        [-1.3652e+01, -1.7540e-02, -4.8227e+00, -6.1809e+00, -1.2476e+01,\n",
       "         -9.0704e+00, -7.8224e+00, -9.3075e+00, -5.0578e+00, -8.1036e+00],\n",
       "        [-6.3382e+00, -3.3802e+00, -3.2622e+00, -3.1918e+00, -5.3655e+00,\n",
       "         -2.8436e+00, -2.4518e-01, -6.8031e+00, -3.6130e+00, -4.4866e+00],\n",
       "        [-1.0084e+01, -9.4367e+00, -5.4741e+00, -7.8941e-03, -1.2882e+01,\n",
       "         -6.7637e+00, -6.4357e+00, -7.2858e+00, -9.9361e+00, -9.8421e+00],\n",
       "        [-1.6592e+01, -1.4529e+01, -6.2997e-04, -7.7387e+00, -2.1501e+01,\n",
       "         -1.9068e+01, -1.2006e+01, -2.4597e+01, -8.5819e+00, -1.8554e+01],\n",
       "        [-9.9948e+00, -1.3913e+01, -8.2798e+00, -5.9357e+00, -6.3854e+00,\n",
       "         -4.3251e+00, -1.0793e+01, -1.1409e+01, -1.9503e-02, -6.5564e+00],\n",
       "        [-1.3403e+01, -1.1434e+01, -1.3261e+01, -8.2199e+00, -3.9533e+00,\n",
       "         -6.5199e+00, -1.0095e+01, -2.6162e+00, -5.2631e+00, -1.0453e-01],\n",
       "        [-7.4755e+00, -8.2978e+00, -5.4825e+00, -5.6275e+00, -4.9767e-01,\n",
       "         -1.9338e+00, -2.6862e+00, -9.2459e+00, -2.6173e+00, -2.3263e+00],\n",
       "        [-1.3780e+01, -1.1736e+01, -9.2198e+00, -5.2017e+00, -4.1807e-02,\n",
       "         -6.7172e+00, -8.2336e+00, -7.3823e+00, -5.7776e+00, -3.5020e+00],\n",
       "        [-1.6922e+01, -6.6255e+00, -2.6855e-02, -3.6874e+00, -1.8514e+01,\n",
       "         -1.3595e+01, -1.1495e+01, -1.4623e+01, -9.0066e+00, -1.4244e+01],\n",
       "        [-5.5793e+00, -1.0274e+01, -1.3973e+00, -3.5824e+00, -2.6081e+00,\n",
       "         -1.8353e+00, -1.4670e+00, -1.1197e+01, -1.3649e+00, -6.2962e+00],\n",
       "        [-7.5256e+00, -1.1489e+01, -1.0602e+01, -7.6995e+00, -3.9175e+00,\n",
       "         -7.1194e+00, -1.2139e+01, -4.8539e-02, -8.7524e+00, -3.6695e+00],\n",
       "        [-9.7258e+00, -1.3907e+01, -7.4601e+00, -5.1472e+00, -9.7260e+00,\n",
       "         -4.1690e+00, -1.4683e+01, -1.4298e+01, -2.2229e-02, -1.2801e+01],\n",
       "        [-7.8555e+00, -1.4464e+01, -1.2858e+01, -7.1379e+00, -1.3208e+00,\n",
       "         -5.4227e+00, -1.1151e+01, -1.0548e+01, -5.3429e+00, -3.2483e-01],\n",
       "        [-1.1763e+01, -3.5478e-02, -6.0570e+00, -5.4043e+00, -9.3960e+00,\n",
       "         -4.6586e+00, -6.3223e+00, -6.5836e+00, -4.2753e+00, -6.6002e+00],\n",
       "        [-1.1765e+01, -1.4782e+01, -7.8623e+00, -1.2396e+01, -1.1243e+01,\n",
       "         -1.2728e+01, -6.3531e-04, -1.7016e+01, -8.4793e+00, -1.1174e+01],\n",
       "        [-1.4225e+01, -8.9542e-03, -6.1435e+00, -6.5354e+00, -1.2362e+01,\n",
       "         -8.4908e+00, -7.8225e+00, -8.4401e+00, -5.4956e+00, -7.8654e+00],\n",
       "        [-7.2063e+00, -8.9944e+00, -5.7010e+00, -7.6191e+00, -7.8544e+00,\n",
       "         -5.1048e+00, -6.9218e+00, -6.6498e+00, -7.2278e-02, -2.8772e+00],\n",
       "        [-5.0959e+00, -5.9352e+00, -7.0629e+00, -3.0145e+00, -5.0589e+00,\n",
       "         -2.0493e-01, -5.7957e+00, -3.7597e+00, -2.9952e+00, -3.1261e+00],\n",
       "        [-1.3794e+01, -3.5018e-02, -7.8260e+00, -3.6479e+00, -1.0394e+01,\n",
       "         -8.3764e+00, -9.4132e+00, -5.6729e+00, -6.5795e+00, -5.8793e+00],\n",
       "        [-1.0745e+00, -6.2489e+00, -2.6069e+00, -3.3666e+00, -6.1394e+00,\n",
       "         -1.5545e+00, -2.8057e+00, -4.5580e+00, -1.4568e+00, -3.4754e+00],\n",
       "        [-9.2535e+00, -1.5876e+01, -9.0902e+00, -1.5933e+01, -1.1602e+01,\n",
       "         -1.1462e+01, -2.8943e-04, -1.9972e+01, -9.8633e+00, -1.1632e+01],\n",
       "        [-1.0975e+01, -1.0735e+01, -1.1074e+01, -6.2675e+00, -2.9595e+00,\n",
       "         -6.7113e+00, -1.0501e+01, -3.0585e+00, -6.5398e+00, -1.0920e-01],\n",
       "        [-5.8171e+00, -1.3233e+01, -4.8155e+00, -9.8083e-02, -1.5847e+01,\n",
       "         -8.3336e+00, -1.3385e+01, -2.5003e+00, -1.0862e+01, -1.0658e+01],\n",
       "        [-6.3518e+00, -1.0064e+00, -2.7717e+00, -1.8421e+00, -9.4857e+00,\n",
       "         -3.0476e+00, -7.4034e+00, -9.2469e+00, -1.0136e+00, -7.5537e+00],\n",
       "        [-7.5836e+00, -9.8287e+00, -4.9678e+00, -1.0357e+01, -4.5564e+00,\n",
       "         -5.5708e+00, -2.3417e-02, -7.2857e+00, -8.9280e+00, -7.6696e+00],\n",
       "        [-7.8675e+00, -1.1809e+01, -7.5181e+00, -3.3291e+00, -8.0782e+00,\n",
       "         -4.5481e+00, -1.0721e+01, -1.0676e+01, -5.0239e-02, -6.6484e+00],\n",
       "        [-3.0687e-01, -1.0122e+01, -3.3784e+00, -4.8370e+00, -3.7959e+00,\n",
       "         -2.1318e+00, -2.9969e+00, -4.0114e+00, -5.8402e+00, -4.5914e+00],\n",
       "        [-1.2695e+01, -9.6681e+00, -4.8117e+00, -3.5567e+00, -6.2969e+00,\n",
       "         -9.9209e+00, -1.0635e+01, -5.7607e-02, -6.4043e+00, -4.1556e+00],\n",
       "        [-8.3541e+00, -1.3844e+01, -5.4636e+00, -1.1508e+01, -8.9301e+00,\n",
       "         -4.6009e+00, -1.5219e-02, -1.3667e+01, -7.7417e+00, -1.1644e+01],\n",
       "        [-1.3085e+01, -2.5421e-02, -4.4608e+00, -5.7818e+00, -9.0104e+00,\n",
       "         -9.0876e+00, -7.2799e+00, -6.1108e+00, -5.1158e+00, -6.6314e+00],\n",
       "        [-9.7689e+00, -1.0007e+01, -7.1531e+00, -6.3238e+00, -3.6360e+00,\n",
       "         -5.0429e+00, -7.6414e+00, -3.3194e+00, -3.7889e+00, -9.9561e-02],\n",
       "        [-1.6118e+01, -1.1072e+01, -1.3773e+01, -8.1407e+00, -2.0628e-02,\n",
       "         -6.2183e+00, -9.6539e+00, -7.4047e+00, -5.0063e+00, -4.5331e+00],\n",
       "        [-1.4169e+01, -1.8521e+01, -1.1291e+01, -1.2205e+01, -8.9821e+00,\n",
       "         -6.4148e+00, -1.0233e+01, -1.3372e+01, -1.9241e-03, -9.1726e+00],\n",
       "        [-4.1088e+00, -8.2467e+00, -1.0046e+01, -1.6233e+00, -6.8775e+00,\n",
       "         -3.5270e-01, -9.1303e+00, -4.5283e+00, -5.2324e+00, -2.7189e+00],\n",
       "        [-1.0623e+01, -1.5775e+01, -8.3143e+00, -1.2634e+01, -4.0946e+00,\n",
       "         -1.2649e+01, -8.6132e+00, -6.5968e+00, -6.5539e+00, -2.0111e-02],\n",
       "        [-6.2300e+00, -8.7919e+00, -3.2918e+00, -6.6529e+00, -3.4235e+00,\n",
       "         -6.5109e+00, -1.3187e-01, -6.0246e+00, -3.1997e+00, -5.1717e+00],\n",
       "        [-7.6058e+00, -2.3974e+00, -2.9840e+00, -3.4555e-01, -5.1318e+00,\n",
       "         -3.5098e+00, -8.4883e+00, -5.0470e+00, -2.2892e+00, -5.0611e+00],\n",
       "        [-4.9603e+00, -9.6247e+00, -8.0517e+00, -2.1943e-02, -1.4541e+01,\n",
       "         -4.3312e+00, -1.0424e+01, -9.1226e+00, -6.9108e+00, -1.0798e+01],\n",
       "        [-9.1374e+00, -9.1308e+00, -6.1068e+00, -9.0972e+00, -1.2244e-01,\n",
       "         -7.2942e+00, -6.0829e+00, -3.1357e+00, -4.8854e+00, -2.8353e+00],\n",
       "        [-2.3859e+00, -5.5618e+00, -3.0755e+00, -4.6910e-01, -1.1486e+01,\n",
       "         -1.7019e+00, -8.6772e+00, -6.1470e+00, -3.0534e+00, -7.4973e+00],\n",
       "        [-8.6605e+00, -1.1799e+01, -9.5492e+00, -1.9875e-02, -1.0807e+01,\n",
       "         -4.7766e+00, -1.1385e+01, -5.2911e+00, -7.5060e+00, -5.2241e+00],\n",
       "        [-6.0120e+00, -7.2005e+00, -4.9376e+00, -1.7985e-01, -8.3562e+00,\n",
       "         -3.7080e+00, -1.0789e+01, -8.4471e+00, -2.1406e+00, -4.4521e+00],\n",
       "        [-1.1465e+01, -1.3382e+01, -9.3660e+00, -1.3492e+01, -2.4807e-02,\n",
       "         -5.9675e+00, -7.0998e+00, -7.6705e+00, -5.5336e+00, -4.0984e+00],\n",
       "        [-3.0668e+00, -1.3597e+01, -6.2065e+00, -7.2494e+00, -6.8587e+00,\n",
       "         -2.1055e+00, -4.4536e+00, -1.6550e+01, -2.0324e-01, -8.8221e+00],\n",
       "        [-8.1490e+00, -5.7677e+00, -4.1591e+00, -1.2583e+00, -1.6261e+00,\n",
       "         -1.9054e+00, -3.3924e+00, -2.5252e+00, -2.1581e+00, -2.1026e+00],\n",
       "        [-5.9818e+00, -1.0761e+01, -4.3220e+00, -3.9134e+00, -8.3616e+00,\n",
       "         -4.1357e+00, -6.6231e+00, -1.4259e+01, -5.5154e-02, -8.0643e+00],\n",
       "        [-5.3410e+00, -1.0152e+01, -4.9880e+00, -9.2774e+00, -4.7766e+00,\n",
       "         -6.8475e-01, -1.0176e+00, -1.2348e+01, -2.1815e+00, -6.6605e+00],\n",
       "        [-1.3256e+01, -1.6557e+01, -7.9994e+00, -1.5637e+01, -9.4224e+00,\n",
       "         -1.1309e+01, -4.5520e-04, -1.6907e+01, -1.0813e+01, -1.2398e+01],\n",
       "        [-1.0763e+01, -1.5368e+01, -5.4664e+00, -1.0896e+01, -4.3419e+00,\n",
       "         -1.3103e+01, -1.8784e-02, -8.3288e+00, -7.5612e+00, -7.4771e+00],\n",
       "        [-4.6225e+00, -1.1602e+01, -8.0064e+00, -7.1805e+00, -1.2725e+00,\n",
       "         -6.3265e+00, -2.0101e+00, -1.8436e+00, -4.4137e+00, -9.0930e-01],\n",
       "        [-6.8228e+00, -1.6864e+01, -1.0861e+01, -5.3704e+00, -5.3822e+00,\n",
       "         -3.9580e-02, -1.1254e+01, -1.0560e+01, -3.6845e+00, -5.7133e+00],\n",
       "        [-1.3651e+01, -1.7368e-02, -5.9509e+00, -6.1957e+00, -1.1392e+01,\n",
       "         -7.7524e+00, -6.9563e+00, -9.3061e+00, -4.5213e+00, -8.4448e+00],\n",
       "        [-1.0025e+01, -1.3089e+01, -9.3829e+00, -8.0902e+00, -9.4863e+00,\n",
       "         -1.0322e+01, -1.3423e+01, -2.1468e-03, -1.0515e+01, -6.4566e+00],\n",
       "        [-1.2017e+01, -2.7087e-02, -4.1695e+00, -7.1206e+00, -1.1050e+01,\n",
       "         -8.4303e+00, -7.4631e+00, -9.1401e+00, -4.6587e+00, -9.8116e+00]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10]), torch.Size([64]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [torch.argmax(x) for x in out.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eq() received an invalid combination of arguments - got (list), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n * (float other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-6cae48ef6a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eq() received an invalid combination of arguments - got (list), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n * (float other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "y.eq(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  0,  4,  4,  2,  2,  7,  9,  9,  1,  6,  3,  2,\n",
       "         8,  9,  4,  4,  2,  8,  7,  8,  9,  1,  6,  1,  8,  5,\n",
       "         1,  0,  6,  9,  3,  1,  6,  8,  0,  7,  6,  1,  9,  4,\n",
       "         8,  5,  9,  6,  3,  3,  4,  3,  3,  3,  4,  8,  3,  8,\n",
       "         5,  6,  6,  9,  5,  1,  7,  1])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.uint8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[0] == y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1),\n",
       " tensor(1),\n",
       " tensor(0),\n",
       " tensor(4),\n",
       " tensor(4),\n",
       " tensor(2),\n",
       " tensor(2),\n",
       " tensor(7),\n",
       " tensor(9),\n",
       " tensor(9),\n",
       " tensor(1),\n",
       " tensor(6),\n",
       " tensor(3),\n",
       " tensor(2),\n",
       " tensor(8),\n",
       " tensor(9),\n",
       " tensor(4),\n",
       " tensor(4),\n",
       " tensor(2),\n",
       " tensor(8),\n",
       " tensor(7),\n",
       " tensor(8),\n",
       " tensor(9),\n",
       " tensor(1),\n",
       " tensor(6),\n",
       " tensor(1),\n",
       " tensor(8),\n",
       " tensor(5),\n",
       " tensor(1),\n",
       " tensor(0),\n",
       " tensor(6),\n",
       " tensor(9),\n",
       " tensor(3),\n",
       " tensor(1),\n",
       " tensor(6),\n",
       " tensor(8),\n",
       " tensor(0),\n",
       " tensor(7),\n",
       " tensor(6),\n",
       " tensor(1),\n",
       " tensor(9),\n",
       " tensor(4),\n",
       " tensor(8),\n",
       " tensor(5),\n",
       " tensor(9),\n",
       " tensor(6),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(4),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(4),\n",
       " tensor(8),\n",
       " tensor(3),\n",
       " tensor(8),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(9),\n",
       " tensor(5),\n",
       " tensor(1),\n",
       " tensor(7),\n",
       " tensor(1)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8215)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1792/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.93325909419153"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "896**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
